<!DOCTYPE html>
<html>
<head>
    <title>Audio Visualizer</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background: black;
        }
        #info {
            position: fixed;
            top: 10px;
            left: 10px;
            color: white;
            font-family: Arial, sans-serif;
            z-index: 100;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px;
        }
    </style>
</head>
<body>
    <div id="info">
        <div>Select input source and click to start:</div>
        <select id="audioSource" style="margin: 10px 0; padding: 5px; background: rgba(255,255,255,0.9);"></select>
        <div style="margin-top: 10px;">
            <label for="gainControl">Gain: </label>
            <input type="range" id="gainControl" min="0" max="200" value="100" style="width: 150px; background: rgba(255,255,255,0.9);">
            <span id="gainValue">100%</span>
        </div>
    </div>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.159.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.159.0/examples/jsm/"
            }
        }
    </script>
    <script type="module">
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

        let scene, camera, renderer, analyser, dataArray, gainNode;
        let line, positions, controls;
        const NUM_POINTS = 256;  // Increased number of points for smoother visualization
        let gainValue = 1.0;

        // Helper function to interpolate between colors
        function lerpColor(value) {
            if (value < 0.5) {
                // Lerp from green to yellow
                return new THREE.Color(value * 2, 1, 0);
            } else {
                // Lerp from yellow to red
                return new THREE.Color(1, 2 - value * 2, 0);
            }
        }

        function init() {
            // Create scene
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // Setup camera and controls
            camera.position.set(6, 4, 6);  // Moved camera back for larger view
            controls = new OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.autoRotate = true;
            controls.autoRotateSpeed = 0.5;
            controls.enableZoom = true;  // Allow zoom for better interaction
            controls.enablePan = false;
            
            // Add additional rotation around other axes
            camera.rotateX(Math.PI / 12);

            // Create line geometry
            const geometry = new THREE.BufferGeometry();
            positions = new Float32Array(NUM_POINTS * 3);
            
            for(let i = 0; i < NUM_POINTS; i++) {
                const x = (i / NUM_POINTS) * 8 - 4; // Straight line from -4 to 4, doubled size
                positions[i * 3] = x;
                positions[i * 3 + 1] = 0;
                positions[i * 3 + 2] = 0;
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('color', new THREE.BufferAttribute(new Float32Array(NUM_POINTS * 3), 3));
            
            const material = new THREE.LineBasicMaterial({ 
                vertexColors: true,
                linewidth: 3,  // Thicker line
                opacity: 0.8,
                transparent: true
            });

            line = new THREE.Line(geometry, material);
            scene.add(line);

            // Handle window resize
            window.addEventListener('resize', onWindowResize, false);
        }

        let audioContext;
        let currentStream = null;

        async function getAudioDevices() {
            const devices = await navigator.mediaDevices.enumerateDevices();
            const audioInputs = devices.filter(device => device.kind === 'audioinput');
            const select = document.getElementById('audioSource');
            select.innerHTML = '';
            
            // Add "No input" option
            const noInputOption = document.createElement('option');
            noInputOption.value = '';
            noInputOption.text = '-- No input --';
            select.appendChild(noInputOption);
            
            audioInputs.forEach(device => {
                const option = document.createElement('option');
                option.value = device.deviceId;
                option.text = device.label || `Microphone ${select.length}`;
                select.appendChild(option);
            });
        }

        async function initAudio() {
            // Clean up existing resources
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                currentStream = null;
            }
            
            if (audioContext) {
                await audioContext.close();
                audioContext = null;
                analyser = null;
            }

            const deviceId = document.getElementById('audioSource').value;
            if (!deviceId) {
                return; // Exit if no device selected
            }

            try {
                // Create new audio context
                audioContext = new AudioContext();
                
                currentStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        deviceId: {exact: deviceId}
                    }
                });
                
                const source = audioContext.createMediaStreamSource(currentStream);
                gainNode = audioContext.createGain();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;  // Increased for better frequency resolution
                source.connect(gainNode);
                gainNode.connect(analyser);
                dataArray = new Uint8Array(analyser.frequencyBinCount);
                animate();
            } catch (err) {
                console.error('Error accessing audio:', err);
                // Clean up on error
                if (currentStream) {
                    currentStream.getTracks().forEach(track => track.stop());
                    currentStream = null;
                }
                if (audioContext) {
                    await audioContext.close();
                    audioContext = null;
                }
                analyser = null;
                throw err; // Rethrow to handle in caller
            }
        }

        function onWindowResize() {
            const width = window.innerWidth;
            const height = window.innerHeight;
            camera.aspect = width / height;
            camera.updateProjectionMatrix();
            renderer.setSize(width, height);
            
            // Adjust camera distance based on window size
            const size = Math.min(width, height);
            camera.position.multiplyScalar(size / 1000);  // Scale camera position with window size
            camera.updateProjectionMatrix();
        }

        function updateLine() {
            if (analyser) {
                analyser.getByteFrequencyData(dataArray);
                const colors = line.geometry.attributes.color.array;
                
                for(let i = 0; i < NUM_POINTS; i++) {
                    // Apply frequency-dependent scaling
                    const freqScale = 1.0 + (i / NUM_POINTS);  // Higher frequencies get boosted
                    const value = (dataArray[i] / 255.0) * gainValue * freqScale * 1.5;  // Overall height increased
                    const x = (i / NUM_POINTS) * 8 - 4;  // Match initial size
                    
                    positions[i * 3] = x;
                    positions[i * 3 + 1] = value;
                    positions[i * 3 + 2] = 0;
                    
                    const color = lerpColor(Math.min(value, 1.0));
                    colors[i * 3] = color.r;
                    colors[i * 3 + 1] = color.g;
                    colors[i * 3 + 2] = color.b;
                }

                line.geometry.attributes.position.needsUpdate = true;
                line.geometry.attributes.color.needsUpdate = true;
            }
        }

        function animate() {
            requestAnimationFrame(animate);
            updateLine();
            
            // Rotate camera in a more dynamic pattern based on audio intensity
            let avgIntensity = 0;
            for(let i = 0; i < NUM_POINTS; i++) {
                avgIntensity += dataArray[i];
            }
            avgIntensity = (avgIntensity / NUM_POINTS) / 255.0;
            
            camera.position.applyAxisAngle(new THREE.Vector3(1, 0, 0), 0.001 * (1 + avgIntensity));
            camera.position.applyAxisAngle(new THREE.Vector3(0, 1, 0), 0.002 * (1 + avgIntensity));
            camera.lookAt(0, 0, 0);
            
            controls.update();
            renderer.render(scene, camera);
        }

        init();

        // Setup gain control
        const gainControl = document.getElementById('gainControl');
        const gainValueDisplay = document.getElementById('gainValue');
        gainControl.addEventListener('input', (e) => {
            gainValue = e.target.value / 100;
            gainValueDisplay.textContent = e.target.value + '%';
            if (gainNode) {
                gainNode.gain.value = gainValue;
            }
        });

        // Request permission and enumerate devices on page load
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                stream.getTracks().forEach(track => track.stop());
                return getAudioDevices();
            })
            .catch(err => console.error('Error getting initial permissions:', err));

        // Handle device selection changes
        document.getElementById('audioSource').addEventListener('change', async (event) => {
            const deviceId = event.target.value;
            if (!deviceId) {
                // If no device is selected, stop current stream
                if (currentStream) {
                    currentStream.getTracks().forEach(track => track.stop());
                    currentStream = null;
                }
                return;
            }
            
            try {
                await initAudio();
                // Don't hide the info div - keep it visible for future selections
            } catch (err) {
                console.error('Error initializing audio:', err);
            }
        });

        // Start audio processing when clicked, but only if no device is selected yet
        document.addEventListener('click', () => {
            if (!analyser && !currentStream) {
                initAudio().catch(err => console.error('Error initializing audio:', err));
            }
        });
    </script>
</body>
</html>
